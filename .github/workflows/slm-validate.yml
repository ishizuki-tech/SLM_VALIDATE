name: SLM Validate

on:
  workflow_dispatch:
  push:
    paths:
      - 'download.sh'
      - 'main.py'
      - 'prompts.yaml'
      - '_input_survey_.jsonl'
      - 'jsonl_to_readme.py'
      - 'all_prompts_to_readme.py'
      - 'requirements.txt'
      - '.github/workflows/slm-validate.yml'

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    permissions:
      contents: write

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            pip install -U llama-cpp-python rich pyyaml
          fi

      - name: Cache models
        uses: actions/cache@v4
        with:
          path: models
          key: models-${{ runner.os }}-${{ hashFiles('download.sh') }}
          restore-keys: |
            models-

      - name: Run download.sh
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        shell: bash
        run: |
          set -euo pipefail
          chmod +x download.sh
          ./download.sh -d models --verify

      - name: Clean previous outputs
        shell: bash
        run: |
          set -euo pipefail
          rm -f OUT_results.jsonl OUT_results.csv OUT_eval_results.yaml OUT_README.md OUT_PROMPTS.md OUT_all_prompts.jsonl || true
          rm -rf logs runs || true
          mkdir -p logs runs

      - name: Run evaluator (batch)
        shell: bash
        env:
          # prevent some BLAS libs from over-threading on GitHub runners
          OMP_NUM_THREADS: 1
          OPENBLAS_NUM_THREADS: 1
          MKL_NUM_THREADS: 1
          VECLIB_MAXIMUM_THREADS: 1
          NUMEXPR_NUM_THREADS: 1
        run: |
          set -euo pipefail
          MODEL_PATH="${MODEL_PATH:-$(ls -1 ./models/*.gguf 2>/dev/null | head -n1 || true)}"
          if [ -z "${MODEL_PATH:-}" ]; then
            echo "ERROR: No .gguf model found under ./models" >&2
            exit 1
          fi
          echo "Using model: $MODEL_PATH"
          if [ ! -f _input_survey_.jsonl ]; then
            echo "ERROR: _input_survey_.jsonl not found" >&2
            exit 1
          fi
          if [ ! -f prompts.yaml ]; then
            echo "ERROR: prompts.yaml not found" >&2
            exit 1
          fi
          python main.py \
            --model "$MODEL_PATH" \
            --input-jsonl _input_survey_.jsonl \
            --out-yaml OUT_eval_results.yaml \
            --output-jsonl OUT_results.jsonl \
            --prompts-jsonl OUT_all_prompts.jsonl \
            --out-csv OUT_results.csv \
            --quiet-batch

      - name: Generate OUTPUT from JSONL
        shell: bash
        run: |
          set -euo pipefail
          if [ -f jsonl_to_readme.py ]; then
            python jsonl_to_readme.py OUT_results.jsonl --out OUT_README.md --title "QA Evaluation Results (Model-Only)."
          else
            echo "jsonl_to_readme.py not found, skipping."
          fi

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        if: ${{ always() }}
        with:
          name: slm-results
          path: |
            OUT_results.jsonl
            OUT_results.csv
            OUT_eval_results.yaml
            OUT_README.md
          if-no-files-found: ignore

      - name: Generate PROMPTS.md (optional)
        if: ${{ success() && hashFiles('all_prompts_to_readme.py') != '' }}
        shell: bash
        run: |
          set -euo pipefail
          python all_prompts_to_readme.py OUT_all_prompts.jsonl OUT_PROMPTS.md || true

      - name: Upload prompts README (optional)
        uses: actions/upload-artifact@v4
        if: ${{ always() }}
        with:
          name: slm-prompts
          path: OUT_PROMPTS.md
          if-no-files-found: ignore

      - name: Show outputs & git status (debug)
        if: ${{ success() }}
        shell: bash
        run: |
          set -euo pipefail
          echo "== ls -al =="
          ls -al
          echo "== git status (before) =="
          git status
          echo "== preview add (intent-to-add) =="
          git add -N OUT_* || true
          git status

      - name: Commit outputs back to repo
        if: ${{ success() }}
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "CI: update outputs from JSONL"
          add_options: "-A"
          file_pattern: "OUT_*"
